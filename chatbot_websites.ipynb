{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Loading URLs into Smaller Documents\n",
    "#       - Load URL\n",
    "#       - Split document into chunks\n",
    "#       - Create text embeddings with OpenAI\n",
    "#\n",
    "# 2. Storing Embeddings in Pinecone\n",
    "# 3. Defining the Retriever\n",
    "# 4. Creating the QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install openai\n",
    "# !pip install pinecone-client\n",
    "# !pip install tiktoken\n",
    "# !pip install selenium langchain-pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"YOUR_PINECONE_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    'https://www.apollodiagnostics.in/blog/10-benefits-of-fruits-in-our-life',\n",
    "    'https://www.healthline.com/nutrition/healthy-fruit'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import SeleniumURLLoader\n",
    "\n",
    "loader = SeleniumURLLoader(urls=urls)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    \n",
    "    separator = '\\n',\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 150\n",
    "    \n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "model_name = \"text-embedding-ada-002\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    \n",
    "    model = model_name,\n",
    "    openai_api_key = openai_api_key\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "region = 'us-east-1'\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "index_name = \"langchain-chatbot\"\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        \n",
    "        name = index_name,\n",
    "        metric = 'cosine',\n",
    "        dimension = 1536,\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=region)\n",
    "        \n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = PineconeVectorStore.from_documents(docs, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "llm_name = 'gpt-3.5-turbo'\n",
    "\n",
    "qa_chain = RetrievalQAWithSourcesChain.from_llm(\n",
    "    \n",
    "    ChatOpenAI(temperature=0, model=llm_name, openai_api_key=openai_api_key),\n",
    "    retriever = retriever\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the benefits of fruits?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"question\": question})\n",
    "\n",
    "print(\"Answer:\", result[\"answer\"])\n",
    "print(\"Sources:\", result[\"sources\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
